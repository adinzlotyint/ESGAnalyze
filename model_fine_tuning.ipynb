{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45313287",
   "metadata": {},
   "source": [
    "## **3. Fine-tuning modelu**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aec4f4",
   "metadata": {},
   "source": [
    "### **Uwaga!**\n",
    "Ze względu na poufność danych, surowe raporty i adnotacje ekspertów nie są zawarte w tym repozytorium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb559f",
   "metadata": {},
   "source": [
    "### **Problem:** \n",
    "Wieloetykietowa klasyfikacja długich, nieustrukturyzowanych dokumentów w języku polskim, w warunkach silnego niezbalansowania klas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ceb68",
   "metadata": {},
   "source": [
    "### **Model enkodera:** sdadas/polish-longformer-base-4096 (https://huggingface.co/sdadas/polish-longformer-base-4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407d1f1",
   "metadata": {},
   "source": [
    "#### **Import Bibliotek**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from datasets import load_from_disk, Dataset\n",
    "from sklearn.metrics import f1_score, accuracy_score, jaccard_score, hamming_loss\n",
    "from transformers import (\n",
    "    LongformerForSequenceClassification,\n",
    "    LongformerTokenizerFast,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    LongformerConfig,\n",
    "    default_data_collator,\n",
    "    EvalPrediction,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb739a",
   "metadata": {},
   "source": [
    "#### **3.1. Definicja parametrów treningu oraz stałych.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ac528",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZED_DATA_PATH = \"data/data_tokenized\"\n",
    "MODEL_NAME = \"sdadas/polish-longformer-base-4096\"\n",
    "MODEL_OUTPUT_BASE_PATH = \"models\"\n",
    "MLFLOW_EXPERIMENT_NAME = \"ESGAnalyzeModel-Training\"\n",
    "\n",
    "CRITERIA_NAMES = [\n",
    "    'c1_transition_plan',\n",
    "    'c2_risk_management',\n",
    "    'c4_boundaries',\n",
    "    'c6_historical_data',\n",
    "    'c7_intensity_metrics',\n",
    "    'c8_targets_credibility',\n",
    "]\n",
    "\n",
    "NUM_LABELS = len(CRITERIA_NAMES)\n",
    "\n",
    "TRAINING_ARGS_DICT = {\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 8,\n",
    "    \"num_train_epochs\": 0,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"warmup_ratio\": 0.1,\n",
    "    \"fp16\": True,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"eval_steps\": 100,\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 100,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"logging_steps\": 25,\n",
    "    \"metric_for_best_model\": \"f1_macro\",\n",
    "    \"greater_is_better\": True,\n",
    "    \"save_total_limit\": 3,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"report_to\": \"mlflow\",\n",
    "    \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87f425",
   "metadata": {},
   "source": [
    "#### **3.2. Wczytanie tokenizowanego zbioru.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe845134",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = load_from_disk(TOKENIZED_DATA_PATH)\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf039c68",
   "metadata": {},
   "source": [
    "#### **3.3. Konfiguracja MLflow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f944db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "w = WorkspaceClient()\n",
    "user_email = w.current_user.me().user_name\n",
    "experiment_path = f\"/Users/{user_email}/{MLFLOW_EXPERIMENT_NAME}\"\n",
    "mlflow.set_experiment(experiment_path)\n",
    "\n",
    "print(f\"Pomyślnie ustawiono eksperyment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb91dd",
   "metadata": {},
   "source": [
    "## **Sekcja treningu**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21272f1",
   "metadata": {},
   "source": [
    "#### **3.4. Przygotowanie komponentów do treningu i ewaluacji.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da8bb45",
   "metadata": {},
   "source": [
    "Funkcja do obliczenia bazowych wag klas na podstawie częstości występowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b74c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(dataset: Dataset) -> torch.Tensor:\n",
    "    labels = np.array(dataset['labels'])\n",
    "    pos_counts = np.sum(labels, axis=0)\n",
    "    total_samples = len(labels)\n",
    "    weights = [total_samples / (2 * count + 1e-6) if count > 0 else 1.0 for count in pos_counts]\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aa74ba",
   "metadata": {},
   "source": [
    "Implementacja Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a47c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=3.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            inputs, targets, reduction='none', pos_weight=self.pos_weight\n",
    "        )\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt)**self.gamma * bce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385684e",
   "metadata": {},
   "source": [
    "Niestandardowa klasa Trainer implementuje FocalLoss i ważenie klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e188d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESGTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        adjusted_weights = class_weights.clone()\n",
    "        for i, weight in enumerate(class_weights):\n",
    "            if weight > 2.5:\n",
    "                adjusted_weights[i] = weight * 3.0\n",
    "        self.class_weights = adjusted_weights.to(self.args.device)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = FocalLoss(alpha=0.25, gamma=3.0, pos_weight=self.class_weights)\n",
    "        loss = loss_fct(logits, labels.float())\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830fe611",
   "metadata": {},
   "source": [
    "Funkcja do obliczania metryk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction) -> Dict[str, float]:\n",
    "    logits, labels = p\n",
    "    preds = (1 / (1 + np.exp(-logits)) > 0.5).astype(int)\n",
    "    return {\n",
    "        'f1_macro': f1_score(labels, preds, average='macro', zero_division=0),\n",
    "        'exact_match_ratio': accuracy_score(labels, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc69781",
   "metadata": {},
   "source": [
    "Funkcja do optymalizacji progów klasyfikacyjnych na zbiorze walidacyjnym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b922a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_thresholds(trainer: Trainer, eval_dataset: Dataset) -> np.ndarray:\n",
    "    preds = trainer.predict(eval_dataset)\n",
    "    logits, y_true = preds.predictions, preds.label_ids\n",
    "    y_probs = 1 / (1 + np.exp(-logits))\n",
    "    \n",
    "    optimal_thresholds = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        best_f1, best_thresh = 0, 0.5\n",
    "        for thresh in np.arange(0.1, 0.91, 0.01):\n",
    "            f1 = f1_score(y_true[:, i], (y_probs[:, i] >= thresh).astype(int), zero_division=0)\n",
    "            if f1 > best_f1: best_f1, best_thresh = f1, thresh\n",
    "        optimal_thresholds.append(best_thresh)\n",
    "    return np.array(optimal_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5933d4",
   "metadata": {},
   "source": [
    "Funkcja do ewaluacji na poziomie dokumentów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_document_level(trainer: Trainer, dataset: Dataset, thresholds: np.ndarray) -> Dict[str, float]:\n",
    "    preds = trainer.predict(dataset)\n",
    "    chunk_probs = 1 / (1 + np.exp(-preds.predictions))\n",
    "    \n",
    "    df = pd.DataFrame({'doc_id': dataset['doc_id'], 'probs': list(chunk_probs), 'labels': list(preds.label_ids)})\n",
    "    doc_results_df = df.groupby('doc_id').agg({\n",
    "        'probs': lambda x: np.percentile(np.array(x.tolist()), 90, axis=0), 'labels': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "    doc_probs = np.array(doc_results_df['probs'].tolist())\n",
    "    doc_labels = np.array(doc_results_df['labels'].tolist())\n",
    "    doc_preds = (doc_probs >= thresholds).astype(int)\n",
    "    \n",
    "    results = {'doc_f1_macro': f1_score(doc_labels, doc_preds, average='macro', zero_division=0),\n",
    "                'doc_exact_match_ratio': accuracy_score(doc_labels, doc_preds),\n",
    "                'doc_jaccard_macro': jaccard_score(doc_labels, doc_preds, average='macro', zero_division=0),\n",
    "                'doc_hamming_loss': hamming_loss(doc_labels, doc_preds),\n",
    "                'num_documents': len(doc_results_df)}\n",
    "    f1_per_label = f1_score(doc_labels, doc_preds, average=None, zero_division=0)\n",
    "    for i, f1 in enumerate(f1_per_label): results[f'doc_f1_{CRITERIA_NAMES[i]}'] = f1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb27352",
   "metadata": {},
   "source": [
    "#### **3.5. Inicjalizacja treningu.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dff15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with mlflow.start_run() as run:\n",
    "        run_id = run.info.run_id\n",
    "        \n",
    "        model_config = LongformerConfig.from_pretrained(\n",
    "            MODEL_NAME, num_labels=NUM_LABELS, problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "        model = LongformerForSequenceClassification.from_pretrained(MODEL_NAME, config=model_config)\n",
    "        tokenizer = LongformerTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "        output_dir = Path(MODEL_OUTPUT_BASE_PATH) / f\"run-{run_id}\"\n",
    "        \n",
    "        training_args = TrainingArguments(output_dir=str(output_dir), **TRAINING_ARGS_DICT)\n",
    "        \n",
    "        mlflow.log_params(training_args.to_dict())\n",
    "        mlflow.log_param(\"model_name\", MODEL_NAME)\n",
    "\n",
    "        class_weights = calculate_class_weights(tokenized_datasets['train'])\n",
    "\n",
    "        trainer = ESGTrainer(\n",
    "            model=model, args=training_args,\n",
    "            train_dataset=tokenized_datasets[\"train\"], eval_dataset=tokenized_datasets[\"validation\"],\n",
    "            data_collator=default_data_collator, compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer, class_weights=class_weights,\n",
    "        )\n",
    "        \n",
    "        print(\"Starting model training...\")\n",
    "        trainer.train()\n",
    "        print(\"Training finished.\")\n",
    "\n",
    "        optimal_thresholds = optimize_thresholds(trainer, tokenized_datasets['validation'])\n",
    "        final_doc_results = evaluate_document_level(trainer, tokenized_datasets['test'], optimal_thresholds)\n",
    "\n",
    "        mlflow.log_metrics({f\"optimal_threshold_{k}\": v for k, v in zip(CRITERIA_NAMES, optimal_thresholds)})\n",
    "        mlflow.log_metrics(final_doc_results)\n",
    "        mlflow.log_param(\"aggregation_strategy\", \"90th percentile\")\n",
    "\n",
    "        final_model_dir = trainer.args.output_dir\n",
    "        trainer.save_model(final_model_dir)\n",
    "        tokenizer.save_pretrained(final_model_dir)\n",
    "\n",
    "        with open(Path(final_model_dir) / \"optimal_thresholds.json\", \"w\") as f:\n",
    "            json.dump({name: float(thresh) for name, thresh in zip(CRITERIA_NAMES, optimal_thresholds)}, f, indent=4)\n",
    "        with open(Path(final_model_dir) / \"final_metrics.json\", \"w\") as f:\n",
    "            json.dump(final_doc_results, f, indent=4)\n",
    "\n",
    "        mlflow.log_artifacts(final_model_dir, artifact_path=\"model\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ An unexpected error occurred: {e}\")\n",
    "    raise e\n",
    "finally:\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
