{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45313287",
   "metadata": {},
   "source": [
    "## **4. Fine-tuning modelu**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aec4f4",
   "metadata": {},
   "source": [
    "### **Uwaga!**\n",
    "Ze względu na poufność danych, surowe raporty i adnotacje ekspertów nie są zawarte w tym repozytorium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb559f",
   "metadata": {},
   "source": [
    "### **Problem:** \n",
    "Wieloetykietowa klasyfikacja długich, nieustrukturyzowanych dokumentów w języku polskim, w warunkach silnego niezbalansowania klas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ceb68",
   "metadata": {},
   "source": [
    "### **Model enkodera:** sdadas/polish-longformer-base-4096 (https://huggingface.co/sdadas/polish-longformer-base-4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407d1f1",
   "metadata": {},
   "source": [
    "#### **Import Bibliotek**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb6d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from datasets import load_from_disk, Dataset\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from transformers import (\n",
    "    LongformerForSequenceClassification,\n",
    "    LongformerTokenizerFast,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    LongformerConfig,\n",
    "    default_data_collator,\n",
    "    EvalPrediction,\n",
    "    EarlyStoppingCallback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb739a",
   "metadata": {},
   "source": [
    "#### **Definicja parametrów treningu oraz stałych.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "886ac528",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZED_DATA_PATH = \"data/data_tokenized\"\n",
    "MODEL_NAME = \"sdadas/polish-longformer-base-4096\"\n",
    "MODEL_OUTPUT_BASE_PATH = \"models\"\n",
    "MLFLOW_EXPERIMENT_NAME = \"ESGAnalyzeModel-Training\"\n",
    "\n",
    "CRITERIA_NAMES = [\n",
    "    'c1_transition_plan',\n",
    "    'c2_risk_management',\n",
    "    'c4_boundaries',\n",
    "    'c6_historical_data',\n",
    "    'c7_intensity_metrics',\n",
    "    'c8_targets_credibility',\n",
    "]\n",
    "\n",
    "NUM_LABELS = len(CRITERIA_NAMES)\n",
    "\n",
    "TRAINING_ARGS_DICT = {\n",
    "    \"learning_rate\": 2.21e-05,\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 8,\n",
    "    \"num_train_epochs\": 10,\n",
    "    \"weight_decay\": 0.159,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"warmup_ratio\": 0.1,\n",
    "    \"fp16\": True,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"eval_steps\": 100,\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 100,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"logging_steps\": 25,\n",
    "    \"metric_for_best_model\": \"f1_macro\",\n",
    "    \"greater_is_better\": True,\n",
    "    \"save_total_limit\": 3,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"report_to\": \"mlflow\",\n",
    "    \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87f425",
   "metadata": {},
   "source": [
    "#### **Wczytanie tokenizowanego zbioru.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe845134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'doc_id', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 5070\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['labels', 'doc_id', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1062\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'doc_id', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 929\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = load_from_disk(TOKENIZED_DATA_PATH)\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf039c68",
   "metadata": {},
   "source": [
    "#### **Konfiguracja MLflow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f944db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pomyślnie ustawiono eksperyment\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "w = WorkspaceClient()\n",
    "user_email = w.current_user.me().user_name\n",
    "experiment_path = f\"/Users/{user_email}/{MLFLOW_EXPERIMENT_NAME}\"\n",
    "mlflow.set_experiment(experiment_path)\n",
    "\n",
    "print(f\"Pomyślnie ustawiono eksperyment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb91dd",
   "metadata": {},
   "source": [
    "## **Sekcja treningu**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21272f1",
   "metadata": {},
   "source": [
    "#### **Przygotowanie komponentów do treningu i ewaluacji.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da8bb45",
   "metadata": {},
   "source": [
    "Funkcja do obliczenia bazowych wag klas na podstawie częstości występowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b74c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(dataset: Dataset) -> torch.Tensor:\n",
    "    labels = np.array(dataset['labels'])\n",
    "    pos_counts = np.sum(labels, axis=0)\n",
    "    total_samples = len(labels)\n",
    "    weights = [total_samples / (2 * count + 1e-6) if count > 0 else 1.0 for count in pos_counts]\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aa74ba",
   "metadata": {},
   "source": [
    "Implementacja Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a47c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            inputs, targets, reduction='none', pos_weight=self.pos_weight\n",
    "        )\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt)**self.gamma * bce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385684e",
   "metadata": {},
   "source": [
    "Niestandardowa klasa Trainer implementuje FocalLoss i ważenie klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e188d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESGTrainer(Trainer):\n",
    "    def __init__(self, *args, focal_loss_alpha=0.5, focal_loss_gamma=2.0, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights.to(self.args.device) if class_weights is not None else None\n",
    "        self.loss_fct = FocalLoss(alpha=focal_loss_alpha, gamma=focal_loss_gamma, pos_weight=self.class_weights)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = self.loss_fct(logits, labels.float())\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830fe611",
   "metadata": {},
   "source": [
    "Funkcja do obliczania metryk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd1ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction) -> Dict[str, float]:\n",
    "    logits, labels = p\n",
    "    preds = (1 / (1 + np.exp(-logits)) > 0.5).astype(int)\n",
    "    return {\n",
    "        'f1_macro': f1_score(labels, preds, average='macro', zero_division=0),\n",
    "        'exact_match_ratio': accuracy_score(labels, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc69781",
   "metadata": {},
   "source": [
    "Funkcja do optymalizacji progów klasyfikacyjnych na zbiorze walidacyjnym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b922a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_thresholds(trainer: Trainer, eval_dataset: Dataset) -> np.ndarray:\n",
    "    preds = trainer.predict(eval_dataset)\n",
    "    logits, y_true = preds.predictions, preds.label_ids\n",
    "    y_probs = 1 / (1 + np.exp(-logits))\n",
    "    \n",
    "    optimal_thresholds = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        best_f1, best_thresh = 0, 0.5\n",
    "        for thresh in np.arange(0.1, 0.91, 0.01):\n",
    "            f1 = f1_score(y_true[:, i], (y_probs[:, i] >= thresh).astype(int), zero_division=0)\n",
    "            if f1 > best_f1: best_f1, best_thresh = f1, thresh\n",
    "        optimal_thresholds.append(best_thresh)\n",
    "    return np.array(optimal_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5933d4",
   "metadata": {},
   "source": [
    "Funkcja do ewaluacji na poziomie dokumentów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "436d1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_document_level(trainer: Trainer, dataset: Dataset, thresholds: np.ndarray) -> Dict[str, float]:\n",
    "    preds = trainer.predict(dataset)\n",
    "    chunk_probs = 1 / (1 + np.exp(-preds.predictions))\n",
    "    \n",
    "    df = pd.DataFrame({'doc_id': dataset['doc_id'], 'probs': list(chunk_probs), 'labels': list(preds.label_ids)})\n",
    "    doc_results_df = df.groupby('doc_id').agg({\n",
    "        'probs': lambda x: np.percentile(np.array(x.tolist()), 75, axis=0), 'labels': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "    doc_probs = np.array(doc_results_df['probs'].tolist())\n",
    "    doc_labels = np.array(doc_results_df['labels'].tolist())\n",
    "    doc_preds = (doc_probs >= thresholds).astype(int)\n",
    "    \n",
    "    results = {'doc_f1_macro': f1_score(doc_labels, doc_preds, average='macro', zero_division=0),\n",
    "                'num_documents': len(doc_results_df)}\n",
    "    f1_per_label = f1_score(doc_labels, doc_preds, average=None, zero_division=0)\n",
    "    for i, f1 in enumerate(f1_per_label): results[f'doc_f1_{CRITERIA_NAMES[i]}'] = f1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb27352",
   "metadata": {},
   "source": [
    "#### **Inicjalizacja treningu.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dff15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at sdadas/polish-longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_811/776410605.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `ESGTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "Initializing global attention on CLS token...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1100' max='6340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1100/6340 1:37:10 < 7:43:44, 0.19 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Exact Match Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.091600</td>\n",
       "      <td>0.090634</td>\n",
       "      <td>0.182103</td>\n",
       "      <td>0.016008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.090735</td>\n",
       "      <td>0.513753</td>\n",
       "      <td>0.009416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.092860</td>\n",
       "      <td>0.611876</td>\n",
       "      <td>0.035782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.088601</td>\n",
       "      <td>0.659493</td>\n",
       "      <td>0.141243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.090005</td>\n",
       "      <td>0.658953</td>\n",
       "      <td>0.144068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.091131</td>\n",
       "      <td>0.690315</td>\n",
       "      <td>0.143126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.083919</td>\n",
       "      <td>0.728494</td>\n",
       "      <td>0.232580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.751934</td>\n",
       "      <td>0.285311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.096516</td>\n",
       "      <td>0.742708</td>\n",
       "      <td>0.269303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.098177</td>\n",
       "      <td>0.743463</td>\n",
       "      <td>0.264595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.102970</td>\n",
       "      <td>0.747070</td>\n",
       "      <td>0.289077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020ca0b3b48b403c9808141f8c7f6efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a01f80ed2274907a132d6273cdf06cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading models/run-21b6e434b35f4028a784f1c0711662a1/model.safetensors:   0%|          | 0.00/566M [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccad962375c4437a830341df33def0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading models/run-21b6e434b35f4028a784f1c0711662a1/checkpoint-1000/model.safetensors:   0%|          | 0.00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ff55d29ee9402ba37eae4e21d3509d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading models/run-21b6e434b35f4028a784f1c0711662a1/checkpoint-1000/optimizer.pt:   0%|          | 0.00/1.11…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f48d9f77034e2da0e1cb960f37e5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading models/run-21b6e434b35f4028a784f1c0711662a1/checkpoint-800/model.safetensors:   0%|          | 0.00/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f89d89389c541739da76ecaffca96a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading models/run-21b6e434b35f4028a784f1c0711662a1/checkpoint-800/optimizer.pt:   0%|          | 0.00/1.11G…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402f9b355cbc4e26bfeb75a84ddeae0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading models/run-21b6e434b35f4028a784f1c0711662a1/checkpoint-1100/model.safetensors:   0%|          | 0.00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3869a197f88942d88e310357f0b94116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading models/run-21b6e434b35f4028a784f1c0711662a1/checkpoint-1100/optimizer.pt:   0%|          | 0.00/1.11…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run respected-cub-733 at: https://dbc-26ad907d-404c.cloud.databricks.com/ml/experiments/1527560425643185/runs/21b6e434b35f4028a784f1c0711662a1\n",
      "🧪 View experiment at: https://dbc-26ad907d-404c.cloud.databricks.com/ml/experiments/1527560425643185\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with mlflow.start_run() as run:\n",
    "        run_id = run.info.run_id\n",
    "        \n",
    "        model_config = LongformerConfig.from_pretrained(\n",
    "            MODEL_NAME, num_labels=NUM_LABELS, problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "        model = LongformerForSequenceClassification.from_pretrained(MODEL_NAME, config=model_config)\n",
    "        tokenizer = LongformerTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "        output_dir = Path(MODEL_OUTPUT_BASE_PATH) / f\"run-{run_id}\"\n",
    "        \n",
    "        training_args = TrainingArguments(output_dir=str(output_dir), **TRAINING_ARGS_DICT)\n",
    "        \n",
    "        mlflow.log_params(training_args.to_dict())\n",
    "        mlflow.log_param(\"model_name\", MODEL_NAME)\n",
    "\n",
    "        class_weights = calculate_class_weights(tokenized_datasets['train'])\n",
    "\n",
    "        trainer = ESGTrainer(\n",
    "            model=model, args=training_args,\n",
    "            train_dataset=tokenized_datasets[\"train\"], eval_dataset=tokenized_datasets[\"validation\"],\n",
    "            data_collator=default_data_collator, compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer, class_weights=class_weights,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "        )\n",
    "        \n",
    "        print(\"Starting model training...\")\n",
    "        trainer.train()\n",
    "        print(\"Training finished.\")\n",
    "\n",
    "        optimal_thresholds = optimize_thresholds(trainer, tokenized_datasets['validation'])\n",
    "        final_doc_results = evaluate_document_level(trainer, tokenized_datasets['test'], optimal_thresholds)\n",
    "\n",
    "        mlflow.log_metrics({f\"optimal_threshold_{k}\": v for k, v in zip(CRITERIA_NAMES, optimal_thresholds)})\n",
    "        mlflow.log_metrics(final_doc_results)\n",
    "        mlflow.log_param(\"aggregation_strategy\", \"75th percentile\")\n",
    "        mlflow.log_param(\"loss function\", \"FocalLoss\")\n",
    "\n",
    "        final_model_dir = trainer.args.output_dir\n",
    "        trainer.save_model(final_model_dir)\n",
    "        tokenizer.save_pretrained(final_model_dir)\n",
    "\n",
    "        with open(Path(final_model_dir) / \"optimal_thresholds.json\", \"w\") as f:\n",
    "            json.dump({name: float(thresh) for name, thresh in zip(CRITERIA_NAMES, optimal_thresholds)}, f, indent=4)\n",
    "        with open(Path(final_model_dir) / \"final_metrics.json\", \"w\") as f:\n",
    "            json.dump(final_doc_results, f, indent=4)\n",
    "\n",
    "        mlflow.log_artifacts(final_model_dir, artifact_path=\"model\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ An unexpected error occurred: {e}\")\n",
    "    raise e\n",
    "finally:\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
